# -*- coding: utf-8 -*-
"""SR_KN_Datathon@LISH (Track Euler).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EmwPEUntXVKFLJ10LBzCk2CG_wYwxkyt

# **Welcome to the Datathon@LISH Colab Notebook**

This is the official contest notebook template for the [Datathon@LISH](https://www.datathonatlish.com/). Use this notebook to compete in the competition!

If you've never used Colab before, don't worry - it's basically a cloud-based Jupyter notebook. Here are some simple instructions to get you started:
*   Double-click on a cell to edit it. To run a cell, either press the "play" button on the left, or press "Ctrl/Cmd" + "Enter".
*   To open the table of contents for the notebook, click the "Table of contents" button in the top left (above the &#128269;)
*   [Use "Ctrl/Cmd + m" then "h"](https://tuewithmorris.medium.com/google-colab-notebooks-keyboard-shortcuts-aa6a008fb91b) to pull up a quick overview of the main keyboard shortcuts. 
*   We recommend just playing around to get familiar. However, if you want a more systematic introduction, you can find more information on [the official Colab tutorial](https://colab.research.google.com/?utm_source=scs-index).

# **Competition Rules and Submission Process for the Datathon@LISH**

## Setting Up Your Notebook and Sharing It with Us (*Important*)

You'll need to make a copy of this notebook (stored in your personal google drive) *and* share the notebook with the contest google account (hbs.research.faculty@gmail.com). This is our mechanism for both verifying compliance to contest rules and collecting your code for reseach purposes. In order to do this, complete the following steps:
1. Ensure that you’ve signed into a google account that associates with an email that you shared with us in the pre-contest survey. (This step is important to ensure that we can link the notebook to your pre-contest survey information)
2. 	Create a copy of the notebook in your personal Google Drive folder ([top left of page] File > Save a Copy in Drive), modifying the title to be relatively unique (e.g. adding your initials). [GIF of how to do this.](https://i.imgur.com/Mo4mpdt.mp4)
3. 	Share [top-right of page] the newly created notebook with our contest organizer account (hbs.research.faculty@gmail.com) as an "**Editor**". Note that we will only use code for verifying rule compliance and research analysis, but will not be editing or monitoring the code during the contest - so please feel free to develop code as you would normally. [GIF of how to do this.](https://i.imgur.com/1Zw4yYl.mp4)

This is the last bit of setup you need to do before starting on the problem. Once you’ve completed these steps, you’re all set to get started working!

## Competition Rules *(Please Read Carefully!)*
"""

#@title
from IPython.display import YouTubeVideo
YouTubeVideo('e6OMklcTd5g')

"""<a name="rules"></a>
Our datathon is split across two tracks, each with slightly different rules and with different contest rankings and winners. Your team has been randomly assigned to **Track Euler**, which has the rules listed below. Note that prizes will be awarded *within* your track, so everyone that you are competing against faces the same rules.

+ **Contest Timeline.** You have until 5PM EST on Sunday, February 13th, 2022 to work on the problem. After that time, our kaggle submission website will not accept new predictions. You can see the contest timeline and remaining time in the contest on [our datathon website](https://www.datathonatlish.com/contest-timeline). 
+ **Constraint on Libraries.** You are not allowed to import any machine learning modeling functions from open-source software libraries like `sklearn` or `pytorch`. 
  + You *are* allowed to use any library model functions from  the family of generalized linear models, such as linear and logistic regression. Techniques like regularization are also permitted. You are also allowed to use any functions in libraries associated with non-modeling tasks, such as exploratory data analysis or feature engineering. 
  > For example, you may use functions from the `sklearn.preprocessing` and `sklearn.linear_model` modules, but you may not use the `sklearn.tree` module (which implements the CART algorithm).
  + If you would like to use a machine learning algorithm, you must manually implement that algorithm yourself within this notebook. Copying implementations from pre-existing code is forbidden.
  > For example, if you would like to use a CART model to solve the problem, you must write your own function within this notebook that implements the CART algorithm. 
  +  The list of banned modeling functions includes (but is not limited to): linear/quadratic discriminant analysis, support vector machines, k-nearest neighbors, naïve bayes, CART/decision trees, random forest, gradient boosted trees, and neural networks. See [here](https://docs.google.com/document/d/12ohdKHFzs82t6_8_WR8QHv2edXro9tSAf9xeTO9sYAE/edit?usp=sharing) for a partial list of packages you may not use for this competition.    
+ **Do All of Your Work in This Notebook**. All work you do on the competition must be done within this notebook - you may not use your own integrated development environment (IDE). This includes any exploration of the data or problem space that you conduct before arriving at a final model. You may not copy code or any other information from other sources.
+ **No External Help**. Do not discuss the details of the competition, prediction problem, or data set with anyone else (including other contest participants). All work should be your own (or your competition partner's).
  >You may freely consult textbooks, documentation, and websites such as stack-overflow. 
+ **No Additional Data Sets**. Do not use any additional data sets not already provided in this notebook. You may create new features based on existing features in the provided data.

We will collect contest code at the end of the competition in order to verify rule compliance - if your code breaks any of the rules, then you will excluded from consideration for contest prizes.

## Prizes, Submitting Predictions, and Prize Eligibility
1. Prizes will be awarded within your contest track, based on your performance in the out-of-sample holdout vs others in the same track. This means that you may not be directly competing against some of your friends; however, it also means there’s less competition and a better chance for you to win a prize!
2. Your predictions must be submitted to Kaggle to be counted towards a prize. As you work on the problem within this notebook, you can make multiple submissions to the prediction competition hosted on Kaggle [here](https://www.kaggle.com/t/e44307d444a341b9bef28344ce90014c). The **Submit to Competition** section at the bottom of the notebook contains instructions and code snippets for exporting and submitting your predictions.
2. The prizes (for each track) are as follows: 
  - First Prize: \$1000 Cash
  - Second Prize: \$500 Cash
  - Third Prize: \$250 Cash
  - Top-Ten (Places 4th through 10th): \$50 Amazon Gift Card
  - Participation Prize: \$10 Amazon Gift Card
3. In order to be eligible to receive contest prizes, you (or your partner) must over 18 years old and be an affiliate of a US-based university. To win a cash prize, you must additionally be eligible to work in the USA (i.e. have a SSN). In addition, the following conditions must hold:
  1.  Completion of the Pre- and Post- Contest Surveys
  2.  You Shared Your Colab Notebook with hbs.research.faculty@gmail.com.
  3.  You Submitted a Kaggle Submission on your assigned Contest Track that beats the competition baseline score.
  4.  You Code passes our automated Rule Checker, which will enforce contest rules (listed above).

  We will send status check emails periodically throughout the contest to ensure that you have opportunities to complete all of these steps!

# **Data Challenge Overview -- Pump it Up: Data Mining the Water Table**

Access to potable water is vital to the health and wellbeing of communities around the world. A smart understanding of which waterpoints will fail can improve maintenance operations and ensure that clean, potable water is available everywhere.  In this competition, you will develop a predictive model that solve binary classification task focused on predicting the operational status of water pumps throughout Tanzania, based on some the provided information about their installation context. 

We will evaluate prediction quality according to a [Log-Loss Error Function](https://www.kaggle.com/dansbecker/what-is-log-loss). (Note that this is different than Percent Accuracy!) As you know, a good statistical model is paramount for helping organizations allocate maintenance resources effectively. We’ve sourced this problem from our friends at [DrivenData](https://www.drivendata.org/), who are some awesome alumni of Harvard Business School and the School of Engineering and Applied Sciences.

## **Data Dictionary**

**Target Feature**:

`status_group` is the key label that you need to predict. It can take on two possible values:
+ `0` - the waterpoint is operational and there are no repairs needed
+ `1` - the waterpoint needs repairs

**Predictors**:

+ `amount_tsh` - Total static head (amount water available to waterpoint)
+ `date_recorded` - The date the row was entered
+ `funder` - Who funded the well
+ `gps_height` - Altitude of the well
+ `installer` - Organization that installed the well
+ `longitude` - GPS coordinate
+ `latitude` - GPS coordinate
+ `wpt_name` - Name of the waterpoint if there is one
+ `basin` - Geographic water basin
+ `subvillage` - Geographic location
+ `region` - Geographic location
+ `region_code` - Geographic location (coded)
+ `district_code` - Geographic location (coded)
+ `lga` - Geographic location
+ `ward` - Geographic location
+ `population` - Population around the well
+ `public_meeting` - True/False
+ `recorded_by` - Group entering this row of data
+ `scheme_management` - Who operates the waterpoint
+ `scheme_name` - Who operates the waterpoint
+ `permit` - If the waterpoint is permitted
+ `construction_year` - Year the waterpoint was constructed
+ `extraction_type` - The kind of extraction the waterpoint uses
+ `extraction_type_group` - The kind of extraction the waterpoint uses
+ `extraction_type_class` - The kind of extraction the waterpoint uses
+ `management` - How the waterpoint is managed
+ `management_group` - How the waterpoint is managed
+ `payment` - What the water costs
+ `payment_type` - What the water costs
+ `water_quality` - The quality of the water
+ `quality_group` - The quality of the water
+ `quantity` - The quantity of water
+ `quantity_group` - The quantity of water
+ `source` - The source of the water
+ `source_type` - The source of the water
+ `source_class` - The source of the water
+ `waterpoint_type` - The kind of waterpoint
+ `waterpoint_type_group` - The kind of waterpoint

# **Your Contest Code**

## **Load Data**

Run the cell below to download and read in the training data.
"""

# Commented out IPython magic to ensure Python compatibility.
# Do not modify this
# %autosave 60 
import gdown
import pandas as pd

# Download the training data from drive
trainURL = "https://drive.google.com/uc?id=11WSDMvwLB5jn3Bjw5KT4LkaIdvtQCl38"
gdown.download(trainURL, "train.csv", quiet=True)

# Read in the training data to a pandas dataframe called train
train = pd.read_csv("train.csv")
train.head()

"""## **Load Packages**

You are free to use external packages to aid in your analyses, but *not* modeling functions (see [above](#rules)).  Please load any and all packages you use in the **Load Packages** section below. Note that many data science packages are already installed in the Colab environment. You may also install additional packages if necessary ([instructions](https://www.kindacode.com/snippet/how-to-install-python-libraries-in-google-colab/)). 
"""

# Load packages here; recall that library functions for machine learning modeling are restricted per contest rules (see above)
import numpy as np
from time import time
import sklearn as sk
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_validate
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_auc_score, roc_curve
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SequentialFeatureSelector
from statsmodels.stats.outliers_influence import variance_inflation_factor

"""## **Your Work**

Use this section to develop your predictive models. You may create additional code cells, and are encouraged to add text cells that explain the steps of your analysis. When you are satisfied with your model, follow the steps in the **Submit to Competition** section to make a submission to our competition on Kaggle.

+ As much as possible, try to group your analyses according to the subheaders within this section. For example, if you choose to do any feature engineering, do it within the *Feature Engineering* section below.

### Exploratory Data Analysis (EDA)
"""

train.dtypes

corr = train.corr()
corr.style.background_gradient(cmap='coolwarm').set_precision(2)

train['date_recorded'] = pd.to_datetime(train['date_recorded'],format='%m/%d/%Y')
train['year'] = pd.DatetimeIndex(train['date_recorded']).year
train['month'] = pd.DatetimeIndex(train['date_recorded']).month
train['day'] = pd.DatetimeIndex(train['date_recorded']).day

#Continuous Variables
train.describe()

#Continuous Variables
cont_df = train.select_dtypes(include=['int64', 'float64']).copy()
continuous_features = cont_df.columns
cont_df, continuous_features

#Categorical Variables
obj_df = train.select_dtypes(include=['object']).copy()
categorical_features = obj_df.columns
obj_df.head(), categorical_features

def preprocessing(df, train = False):
  #change date format
  df['date_recorded'] = pd.to_datetime(df['date_recorded'],format='%m/%d/%Y')
  df['year'] = pd.DatetimeIndex(df['date_recorded']).year
  df['month'] = pd.DatetimeIndex(df['date_recorded']).month
  df['day'] = pd.DatetimeIndex(df['date_recorded']).day

  #select continuous and categorical variables
  cont_df = df.select_dtypes(include=['int64', 'float64']).copy()
  continuous_features = cont_df.columns
  obj_df = df.select_dtypes(include=['object']).copy()
  categorical_features = obj_df.columns

  #missing data imputation
  #continuous variables
  describe_cont = cont_df.describe()
  describe_cont.loc["mean"]
  for col in cont_df:
    cont_df = cont_df.fillna({col: describe_cont.loc["mean"][col]})
  
  #categorical variables
  for feature in categorical_features:
    max_val = obj_df[feature].value_counts().index.tolist()[0]
    obj_df = obj_df.fillna({feature: max_val})

  #categorical features label encoding (skip date_recorded)
  label_encoder = LabelEncoder()
  for col in categorical_features:
    obj_df[col] = label_encoder.fit_transform(obj_df[col])

  #concat the two dfs 
  newTrain = pd.concat([obj_df, cont_df],axis = 1, join = 'outer', ignore_index=False, sort=False)

  newTrain["year"] = df["year"]
  newTrain["month"] = df["month"]
  newTrain["day"] = df["day"]

  stdsc = StandardScaler()

  if train:
    label = newTrain["status_group"]
    newTrain = newTrain.drop("status_group", 1)
    # vif_dataframe = pd.DataFrame(newTrain, columns = vif_var)
    # vif_dataframe = stdsc.fit_transform(vif_dataframe)
    return newTrain, label
  else:
    return newTrain

newTrain, label = preprocessing(train, True)

newTrain

"""### Feature Engineering

1. Missing Data Imputation
2. Categorical Variable Encoding
3. Transformation/Normalization
4. Discretization

**Continuous variables**
"""

#check null values
def check_null(df):
  for colname in df.columns:
    print("Number of null values in", colname, ": ", df[colname].isnull().sum())

describe_cont = cont_df.describe()
describe_cont.loc["mean"]

for col in cont_df:
  cont_df = cont_df.fillna({col: describe_cont.loc["mean"][col]})

cont_df, check_null(cont_df)

"""**Categorical**

Fill in the NA values with most frequently appeard value
"""

#For categorical features, fill in the NA value with the most frequently appeared value
for feature in categorical_features:
  max_val = obj_df[feature].value_counts().index.tolist()[0]
  obj_df = obj_df.fillna({feature: max_val})

check_null(obj_df)

# Label encode categorical features (skip date_recorded)
label_encoder = LabelEncoder()
for col in categorical_features:
  obj_df[col] = label_encoder.fit_transform(obj_df[col])

obj_df

newTrain = pd.concat([obj_df, cont_df],axis = 1, join = 'outer', ignore_index=False, sort=False)
newTrain["year"] = train["year"]
newTrain["month"] = train["month"]
newTrain["day"] = train["day"]

newTrain

label = newTrain["status_group"]
newTrain = newTrain.drop("status_group", 1)

def calc_vif(X):
    # Calculating VIF
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
    return(vif)

vif_df = calc_vif(newTrain)

vif_df

# selecting rows based on condition
rslt_df = vif_df.loc[vif_df['VIF'] < 10]
vif_var = rslt_df["variables"].to_numpy()

#Normalization data
stdsc = StandardScaler()
vif_dataframe = pd.DataFrame(newTrain, columns = vif_var)
vif_dataframe = stdsc.fit_transform(vif_dataframe)

newTrain

corr = newTrain.corr()
corr.style.background_gradient(cmap='coolwarm').set_precision(2)

# feature_names = np.array(newTrain.columns)
vif_dataframe = pd.DataFrame(newTrain, columns = vif_var)
vif_dataframe = stdsc.fit_transform(vif_dataframe)



lg_model = LogisticRegression()

#Feature selection
tic_fwd = time()
sfs_forward = SequentialFeatureSelector(
    lg_model, n_features_to_select=20, direction="forward"
).fit(newTrain, label)
toc_fwd = time()

# tic_bwd = time()
# sfs_backward = SequentialFeatureSelector(
#     lg_model, n_features_to_select=20, direction="backward"
# ).fit(X_train, y_train)
# toc_bwd = time()

print(
    "Features selected by forward sequential selection: "
    f"{feature_names[sfs_forward.get_support()]}"
)
print(f"Done in {toc_fwd - tic_fwd:.3f}s")
# print(
#     "Features selected by backward sequential selection: "
#     f"{feature_names[sfs_backward.get_support()]}"
# )
# print(f"Done in {toc_bwd - tic_bwd:.3f}s")

"""### Model Building"""

# Add code here to build your predictive models
# trainX = newTrain.to_numpy()
trainX = vif_dataframe
trainY = label.to_numpy()

trainX.shape, trainY.shape

X_train, X_test, y_train, y_test = train_test_split(trainX, trainY, test_size=0.2, random_state=42)

lg_model = LogisticRegression()
lg_model.fit(X_train, y_train)

lg_ytrain_pred = lg_model.predict_proba(X_train)
print("LG Train roc-auc:{}".format(roc_auc_score(y_train, lg_ytrain_pred[:,1])))

lg_y_test_pred = lg_model.predict_proba(X_test)
print("LG Test roc-auc:{}".format(roc_auc_score(y_test, lg_y_test_pred[:,1])))

pred = []

for model in [lg_model]:
    pred.append(pd.Series(model.predict_proba(X_test)[:,1]))

final_pred = pd.concat(pred, axis=1).mean(axis=1)
print("Ensemble test roc-auc:{}".format(roc_auc_score(y_test,final_pred)))

False_pos_rate, True_pos_rate, threshold = roc_curve(y_test, final_pred)

threshold

from sklearn.metrics import accuracy_score

acc = []

for thres in threshold:
    y_pred = np.where(final_pred>thres,1,0)

    #what ever prediction i am getting and if it is greater than threshold i'll be converting as 1 or i'll keep it as 0.

    acc.append(accuracy_score(y_test,y_pred,normalize=True))

    #Then i'll be computing my accuracy score with my y_test and then
    #append the accuracy inside acc list.

acc = pd.concat([pd.Series(threshold), pd.Series(acc)], axis=1)
acc.columns = ['threshold','accuracy']
acc.sort_values(by="accuracy", ascending=False, inplace = True)
acc

thres = acc["threshold"][1049]

y_pred = ((model.predict_proba(X_test)[:, 1])>= thres).astype(int)

#Confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=clf1.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                             display_labels=clf1.classes_)
disp.plot()
plt.show()

acc = sum(y_test == y_pred)/len(y_test)
acc

clf1 = LogisticRegression(penalty = "l2").fit(trainX, trainY)
clf2 = LogisticRegression(penalty = "none").fit(trainX, trainY)

# get importance
importance = clf1.coef_[0]
# summarize feature importance
for i,v in enumerate(importance):
	print('Feature: %0d, Score: %.5f' % (i,v))

clf1.score(trainX, trainY), clf2.score(trainX, trainY)

predict = clf1.predict(trainX)

"""### Model Evaluation"""

import warnings
warnings.filterwarnings('ignore')

#k fold cross-validation
def k_fold_cv(model, k, X, Y):
  cv_results = cross_validate(model, X, Y, cv=k)
  result = np.mean(cv_results['test_score'])
  return result

k_fold_cv(clf1, 10, trainX, trainY)

k_fold_cv(clf2, 10, trainX, trainY)

#Confusion matrix
cm = confusion_matrix(label, predict, labels=clf1.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                             display_labels=clf1.classes_)
disp.plot()
plt.show()

"""## **Submit to Competition**

Run the cell below to read in the test set features.

Then, you can use your model to generate predictions on this data, then create a dataframe with the following format / variables:
+ `id` - the unique ID for each observation.
+ `predicted` - your model's predicted probability that a pump needs repair. 

Write this data frame to a csv file called `"submission.csv"`. Then download this file by opening the files pane within Colab (look for the &#128193; symbol on the left of the screen). This is shown in the gif below. 

After downloading the file, make a submission to our [Kaggle competition](https://www.kaggle.com/t/e44307d444a341b9bef28344ce90014c). If you haven't already, you'll need to first sign in on Kaggle and hit "**Join the Competition**" in order to submit. 

**Note:** For your submission to the Kaggle competition, do *not* modify your Kaggle Team Name. This should be the same as the Kaggle Display Name you provided in the Pre-Work Survey so that we can connect your notebook to your submission. 
"""

# Download file with features in the test set
testFeaturesURL = "https://drive.google.com/uc?id=1C64MAXqe4R4UjFBJcyK7hmKcNIVj3C8x"
gdown.download(testFeaturesURL, "test_features.csv", quiet=True)

# Read test set features into a pandas data frame
testFeatures = pd.read_csv("test_features.csv")
testFeatures.head()

testFeatures.shape

# Add code to generate your predictions for the test set here.
test_df = preprocessing(testFeatures)

result = clf2.predict(test_df)
id = np.arange(len(result))

id.shape

# See below for an example of exporting a pandas data frame called "submission" to a csv file. 
df = pd.DataFrame({'id':testFeatures["id"], "predicted":result})
df.to_csv(r"submission.csv", index=False)

#@title
from IPython.display import HTML

HTML("""
<div align="left">
<video width="70%" controls>
      <source src="https://i.imgur.com/GQy0Gm5.mp4" type="video/mp4">
</video></div>""")